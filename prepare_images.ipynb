{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bilder für Identification vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook werden Schritt für Schritt die notwendigen Operationen durchgeführt, um die Bilder für das Trainieren eines Klassifikators vorzubereiten. Eingangs muss der Pfad für die eingehenden Bilder richtig gesetzt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from torchvision import transforms as tr\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Konstanten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Bilder padden und resizen\n",
    "Damit die Bilder für das bestimmen der Bounding-Boxes verwendet werden können, müssen sie zunächt auf die richtige Größe gebracht werden. Um die Seitenverhältnisse nicht zu verzerren, werden die Originalbilder links und rechts mit einem Padding versehen und dann auf die richtig Größe (300x300 Pixel) angepasst. \n",
    "\n",
    "Weiterhin ist wichtig, dass die Ordnerstruktur berücksichtigt wird. Die Unterordner im data-Verzeichnis enthalten immer jeweils Bilder eine individuellen Kuh.\n",
    "\n",
    "TODO: Pfad zum full_sorted Ordner erklaeren und verlinken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH\t= 300\n",
    "IMG_HEIGHT\t= 300\n",
    "\n",
    "INPUT_IMGS_PATH  = 'C:/dev/netcase/cow_dataset/full_sorted/'\n",
    "OUTPUT_IMGS_PATH = 'data/pad_resize/'\n",
    "\n",
    "# Output Ordner erstellen, falls er nicht existiert\n",
    "if not os.path.isdir(OUTPUT_IMGS_PATH):\n",
    "    os.mkdir(OUTPUT_IMGS_PATH)\n",
    "\n",
    "for img_dir in os.listdir(INPUT_IMGS_PATH):\n",
    "    if os.path.isdir(os.path.join(INPUT_IMGS_PATH, img_dir)):\n",
    "        for img_file in os.listdir(os.path.join(INPUT_IMGS_PATH, img_dir)):\n",
    "            \n",
    "            input_path = os.path.join(INPUT_IMGS_PATH, img_dir, img_file)\n",
    "            \n",
    "            # Ordner und Nicht-Bild Dateien überspringen\n",
    "            if not os.path.isdir(input_path) and os.path.splitext(input_path)[-1].lower() == \".jpg\":\n",
    "            \n",
    "                # Vorbereiten der Bilder\n",
    "                image = Image.open(input_path)\n",
    "                image = ImageOps.pad(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                image = image.rotate(90)\n",
    "                \n",
    "                # Ausgabeordner für jeweilige Kuh anlegen\n",
    "                output_dir = os.path.join(OUTPUT_IMGS_PATH, img_dir)\n",
    "                if not os.path.isdir(output_dir):\n",
    "                    os.mkdir(output_dir)\n",
    "                \n",
    "                # Bild speichern\n",
    "                output_path = os.path.join(OUTPUT_IMGS_PATH, img_dir, img_file)\n",
    "                image.save(output_path)\n",
    "\n",
    "                image.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Bounding-Boxes bestimmen und extrahieren\n",
    "Hou et al. (TODO: put link) nutzen in ihrer Implementation des Systems einen Single Shot Multibox Detector (SSD). Diesen selbst aufzusetzen und zu trainieren ist für diese Beipiel allerdings nicht zielführend. NVIDIA bietet hier einen Out-Of-The-Box Lösung (TODO: put link), die wir anwenden, um die Bounding-Boxes zu bestimmen. Da der Detector am COCO Dataset trainiert wurde, kann er Kühe bereits erkennen und benötigt dementsprechend keine weiteren Anpassungen mehr.\n",
    "\n",
    "Der folgende Code ist stark an die Pytorch Anleitung (TODO: put link) angelehnt und unterscheidet sich hauptsächlich darin, dass die generierten Bounding-Boxes genutzt werden, um die Bildausschnitte zu extrahieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Christian/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n",
      "Using cache found in C:\\Users\\Christian/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33465755 0.0676491  0.7200849  0.95493376]\n"
     ]
    }
   ],
   "source": [
    "PAD_IMGS_PATH = 'data/pad_resize/'\n",
    "BOX_IMGS_PATH = 'data/bounding_box/'\n",
    "\n",
    "# create output directory if it does not exist\n",
    "if not os.path.isdir(BOX_IMGS_PATH):\n",
    "    os.mkdir(BOX_IMGS_PATH)\n",
    "\n",
    "# Laden des Models und zusätzlicher Utility \n",
    "ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\n",
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\n",
    "\n",
    "# Konfiguration des Models \n",
    "ssd_model.to('cuda')\n",
    "ssd_model.eval()\n",
    "\n",
    "show_one = True\n",
    "\n",
    "# Pro Kuh, alle Bounding Boxes in den Bildern bestimmen \n",
    "for img_dir in os.listdir(PAD_IMGS_PATH):\n",
    "    # Liste aller Bild-Pfade\n",
    "    uris = []\n",
    "\n",
    "    # Alles Bild-Pfade im Ordner laden \n",
    "    for img_file in os.listdir(os.path.join(PAD_IMGS_PATH, img_dir)):\n",
    "        uris.append(os.path.join(PAD_IMGS_PATH, img_dir, img_file))\n",
    "    \n",
    "    # Vorbereiten der Bilder (vgl. Tutorial) (TODO: put link)\n",
    "    inputs = [utils.prepare_input(uri) for uri in uris]\n",
    "    tensor = utils.prepare_tensor(inputs)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        detections_batch = ssd_model(tensor)\n",
    "\n",
    "    # Resultate verarbeiten (vgl. Tutorial) (TODO: put link)\n",
    "    results_per_input = utils.decode_results(detections_batch)\n",
    "    best_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\n",
    "    classes_to_labels = utils.get_coco_object_dictionary()\n",
    "\n",
    "    # TODO: show a bounding box here as example\n",
    "\n",
    "    for image_idx in range(len(best_results_per_input)):\n",
    "        # Originales, wiederhergestelltes Bild\n",
    "        image = inputs[image_idx] / 2 + 0.5\n",
    "        bboxes, classes, confidences = best_results_per_input[image_idx]\n",
    "\n",
    "        # Bestes Match\n",
    "        max_index = confidences.argmax()\n",
    "        \n",
    "        # Bounding Box extrahieren\n",
    "        # NOTE: Im Vergleich zum Tutorial mussten top und bot getauscht werden, da y=0 normalerweise unten ist.\n",
    "        left, top, right, bot = bboxes[max_index] * 300\n",
    "\n",
    "        # NOTE: Die Pixelwerte in image sind floats und müssen erst in 8-Bit ints umgewandelt werden.\n",
    "        output_image = Image.fromarray((image * 255).astype(np.uint8))\n",
    "        output_image = output_image.crop((left, top, right, bot))\n",
    "\n",
    "        # Zurückschreiben\n",
    "        head, tail = os.path.split(img_dir)\n",
    "        \n",
    "        output_dir = os.path.join(BOX_IMGS_PATH, tail + '/')\n",
    "        if not os.path.isdir(output_dir):\n",
    "            os.mkdir(output_dir)\n",
    "\n",
    "        output_path = os.path.join(BOX_IMGS_PATH, tail + '/', str(image_idx) + '.jpg')\n",
    "        output_image.save(output_path)\n",
    "        output_image.close()\n",
    "\n",
    "    # NOTE: Die Implementation vom SSD scheint den GPU Speicher nicht eigentständig freizugeben. Dementsprechend wird er hier explizit geleert.\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Image Dataset Augmentation\n",
    "Um ausreichendes Bildmaterial zur Verfügung zu haben und Probleme wie Overfitting zu vermeiden, werden nun auf den Datensatz einfache geometrische Transformationen angewendet. Dies ist eine gängige Methode beim Trainieren von Neuronalen Netzen und wurde auch in Hou et al. (TODO: put link) durchgeführt. Hier wurde der Datensatz um das 20-fache vergrößert (TODO: put absolut number as well).\n",
    "\n",
    "In diesem Beispiel wird der Datensatz auf das 8-fache vergrößert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put all constants up to the top and don't re-define them\n",
    "BOX_IMGS_PATH = 'data/bounding_box/'\n",
    "AUG_IMG_PATH  = 'data/augment/'\n",
    "\n",
    "# Anzahl der Kopien pro Bild\n",
    "AUGMENT_FACTOR = 8\n",
    "\n",
    "# Erstellen des Verzeichnises, falls es nicht existiert\n",
    "if not os.path.isdir(AUG_IMG_PATH):\n",
    "    os.mkdir(AUG_IMG_PATH)\n",
    "\n",
    "# Pipeline, um Bilder zu flippen und/oder verzerren \n",
    "applier = tr.RandomApply(transforms=[tr.RandomHorizontalFlip(), \n",
    "                                     tr.RandomPerspective(distortion_scale=0.6, p=1), \n",
    "                                     tr.RandomResizedCrop(size=(224, 224), scale=(0.7, 1.0))], p=1)\n",
    "\n",
    "for img_dir in os.listdir(BOX_IMGS_PATH):\n",
    "    img_index = 0\n",
    "    for img_file in os.listdir(os.path.join(BOX_IMGS_PATH, img_dir)):\n",
    "        to_augment = Image.open(os.path.join(BOX_IMGS_PATH, img_dir, img_file))\n",
    "\n",
    "        # Originales Bild speichern\n",
    "        if not os.path.isdir(os.path.join(AUG_IMG_PATH, img_dir)):\n",
    "            os.mkdir(os.path.join(AUG_IMG_PATH, img_dir))\n",
    "\n",
    "        to_augment.save(os.path.join(AUG_IMG_PATH, img_dir, img_file))\n",
    "\n",
    "        # Augmentation anwenden\n",
    "        augmented_imgs = [applier(to_augment) for _ in range(AUGMENT_FACTOR)] \n",
    "        \n",
    "        # Augmented Bilder speichern\n",
    "        for aug_index in range(len(augmented_imgs)):\n",
    "            img_path = os.path.join(AUG_IMG_PATH, img_dir, 'aug_' + str(img_index) + '_' + str(aug_index) + '.jpg')\n",
    "            augmented_imgs[aug_index].save(img_path)\n",
    "\n",
    "        img_index += 1\n",
    "        to_augment.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e922dd073470bdcc017ae3abd31d6491d6ed7bf31c1d559806e5511bfea88b81"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
